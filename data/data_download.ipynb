{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import quandl\n",
    "import numpy as np\n",
    "from binance.client import Client\n",
    "import pickle\n",
    "from datetime import datetime, date, time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data sources should have date index:\n",
    "def fill_missing_data(df, freq):\n",
    "    idx = pd.date_range(df.index[0], df.index[-1], freq = freq)\n",
    "    try: \n",
    "        print(np.sum(idx == df.index) == df.shape[0])\n",
    "    except:\n",
    "        df = df.reindex(idx, fill_value = np.nan)\n",
    "        df = df.interpolate(method = \"spline\", order = 3, s = 0.)\n",
    "        print(np.sum(idx == df.index) == df.shape[0], \"missing data was corrected\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC Daily and 5-m Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API:\n",
    "binance_api_key = 'Your Binance Api Key'    #Enter your own API-key here\n",
    "binance_api_secret = 'Your Binance Api Key' #Enter your own API-secret here\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "\n",
    "# df_5m:\n",
    "klines = binance_client.get_historical_klines(\"BTCUSDT\", Client.KLINE_INTERVAL_5MINUTE, \"1 Jan, 2017\")\n",
    "df_5m = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "df_5m['timestamp'] = pd.to_datetime(df_5m['timestamp'], unit='ms')\n",
    "\n",
    "# # df_1d:\n",
    "klines = binance_client.get_historical_klines(\"BTCUSDT\", Client.KLINE_INTERVAL_1DAY, \"1 Jan, 2017\")\n",
    "df_1d = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "df_1d['timestamp'] = pd.to_datetime(df_1d['timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create Daily Returns Series:\n",
    "\n",
    "## Create the copy of the raw data and operate on the copy:\n",
    "market_daily = df_1d.copy()\n",
    "\n",
    "## Create returns dataframe from copy:\n",
    "market_daily.set_index(market_daily.timestamp, inplace = True)\n",
    "market_daily.drop(columns=[\"timestamp\"], inplace = True)\n",
    "market_daily = market_daily.astype(float)\n",
    "market_daily = fill_missing_data(market_daily, '1d')\n",
    "btc_ret = pd.DataFrame(100*np.log(market_daily.close/market_daily.close.shift(1)),\\\n",
    "     index = market_daily.index)\n",
    "btc_ret.dropna(inplace = True)\n",
    "btc_ret.index = pd.to_datetime(btc_ret.index).date\n",
    "btc_ret.rename({\"close\":\"returns\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle it for further use in emergency:\n",
    "with open(\"./btc_returns\", \"wb\") as file:\n",
    "    pickle.dump(btc_ret, file)\n",
    "file.close()\n",
    "with open(\"./btc_price_data\", \"wb\") as file:\n",
    "    pickle.dump(market_daily, file)\n",
    "file.close()\n",
    "with open(\"./btc_price_5m\", \"wb\") as file:\n",
    "    pickle.dump(df_5m, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC Realized Volatility: daily, weekly, monthly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True missing data was corrected\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pandas.core import window\n",
    "\n",
    "\n",
    "hf_data = df_5m.copy()\n",
    "hf_data.set_index('timestamp', inplace = True)\n",
    "hf_data = hf_data.astype(float)\n",
    "\n",
    "hf_data = fill_missing_data(hf_data, '5min')\n",
    "\n",
    "hf_ret = pd.DataFrame(100*np.log(hf_data.close.copy()/hf_data.close.copy().shift(1)), \\\n",
    "    index = hf_data.index)\n",
    "# missing = pd.date_range(start = '2017-12-08', end = '2022-06-17' ).difference(hf_ret.index)\n",
    "# print(missing)\n",
    "\n",
    "# Get Daily Realized Volatility:\n",
    "hf_rv = ((hf_ret**2).rolling(window=288).sum())\n",
    "hf_rv.dropna(inplace=True)\n",
    "end_of_the_day = time(23,55,0)\n",
    "rv_daily = hf_rv.loc[end_of_the_day]\n",
    "rv_daily = rv_daily.rename({'close':'rv_d'}, axis = 1)\n",
    "\n",
    "# Check missing and interpolate:\n",
    "rv_daily = fill_missing_data(rv_daily,\"1d\")\n",
    "\n",
    "# Add daily, weekly and monthly to the dataframe:\n",
    "# Put Indices to The Same Formate And Add RV to df_expl:\n",
    "rv_daily.set_index(pd.to_datetime(rv_daily.index).date, inplace=True)\n",
    "\n",
    "# Get weekly realized volatility:\n",
    "rv_weekly = rv_daily.rolling(window = 7).mean()\n",
    "rv_monthly = rv_daily.rolling(window = 30).mean()\n",
    "rv_weekly = fill_missing_data(rv_weekly, \"1d\")\n",
    "rv_monthly = fill_missing_data(rv_monthly, \"1d\")\n",
    "rv_weekly.rename({\"rv_d\":\"rv_w\"}, axis=1, inplace=True)\n",
    "rv_monthly.rename({\"rv_d\":\"rv_m\"}, axis=1, inplace=True)\n",
    "\n",
    "# Put monthly, weekly daily together:\n",
    "rv_total = pd.concat([rv_daily, rv_weekly, rv_monthly, btc_ret], axis = 1)\n",
    "rv_total.dropna(inplace=True)\n",
    "rv_total.index = pd.to_datetime(rv_total.index)\n",
    "# pickle\n",
    "with open(\"./realized_vols\", \"wb\") as file:\n",
    "    pickle.dump(rv_total, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking correctness of aggregation:\n",
    "(hf_ret**2).rolling(288).sum().loc[\"2017-09-18\"].iloc[-1][0] ==\\\n",
    "    (hf_ret.loc[pd.to_datetime(\"2017-09-18 00:00:00\"):\\\n",
    "        pd.to_datetime(\"2017-09-18 23:55:00\")]**2).sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note: No missing value in rv_total!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Economic and Financial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "fred = Fred(api_key='insert your api key')\n",
    "ffer = pd.DataFrame(fred.get_series('dff', observation_start='2000-01-01'),\n",
    " columns = [\"FFER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  9 of 9 completed\n"
     ]
    }
   ],
   "source": [
    "# Stock, Crypto and Commodity Market Data from YF and NASDAQ:\n",
    "data = yf.download(\"CNYUSD=X SPY NDAQ ^DJI CL=F ^VIX ^GVZ XRP-USD BTC=F\", start = \"2000-01-01\")\n",
    "data = data['Adj Close']\n",
    "finecon = pd.concat([ffer, data], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockchain Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids = ['BCHAIN/ATRCT',\t'BCHAIN/AVBLS',\t'BCHAIN/BLCHS',\t'BCHAIN/CPTRA',\t'BCHAIN/CPTRV',\t'BCHAIN/DIFF',\t\n",
    "                    'BCHAIN/ETRAV',\t\n",
    "    'BCHAIN/ETRVU',\t'BCHAIN/HRATE',\t'BCHAIN/MIREV',\t'BCHAIN/MKPRU',\t\n",
    "                    'BCHAIN/MKTCP',\t\n",
    "    'BCHAIN/MWNTD',\t'BCHAIN/MWNUS',\t'BCHAIN/MWTRV',\t'BCHAIN/NADDU',\n",
    "                \t'BCHAIN/NTRAN',\t\n",
    "    'BCHAIN/NTRAT',\t'BCHAIN/NTRBL',\t'BCHAIN/NTREP',\t'BCHAIN/TOTBC',\t'BCHAIN/TOUTV',\t\n",
    "                    'BCHAIN/TRFEE',\t\n",
    "    'BCHAIN/TRFUS',\t'BCHAIN/TRVOU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockchain_info = quandl.get(ids, authtoken=\"insert your authotoken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockchain_info.columns = [ 'ATRCT',\t'AVBLS','BLCHS',\n",
    "\t'CPTRA',\t'CPTRV',\t'DIFF',\t'ETRAV',\t'ETRVU',\t'HRATE',\t'MIREV',\t'MKPRU',\t'MKTCP',\n",
    "    \t'MWNTD',\t'MWNUS',\t'MWTRV',\t'NADDU',\t'NTRAN',\t'NTRAT',\t'NTRBL',\t'NTREP',\t\n",
    "        'TOTBC',\t'TOUTV',\t'TRFEE',\t'TRFUS',\t'TRVOU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATRCT    391\n",
       "AVBLS      2\n",
       "BLCHS      2\n",
       "CPTRA      2\n",
       "CPTRV      5\n",
       "        ... \n",
       "TOTBC      1\n",
       "TOUTV      2\n",
       "TRFEE      2\n",
       "TRFUS      2\n",
       "TRVOU      1\n",
       "Length: 25, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blockchain_info.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risks and Uncertainties"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chine Economic Policy Uncertainty Data:\n",
    "dls = \"https://economicpolicyuncertaintyinchina.weebly.com/uploads/1/2/2/7/122762465/cnepu_daily_18_june_2022_updated.xlsx\"\n",
    "resp = requests.get(dls)\n",
    "\n",
    "output = open('./fin.xlsx', 'wb')\n",
    "output.write(resp.content)\n",
    "output.close()\n",
    "\n",
    "epu = pd.read_excel(\"./fin.xlsx\", parse_dates = [\"Date\"])\n",
    "epu.dropna(inplace=True)\n",
    "epu.Date = pd.to_datetime(epu.Date)\n",
    "epu.set_index(epu.Date, inplace = True)\n",
    "epu.drop(columns = [\"Date\"], inplace = True)\n",
    "np.sum(epu.isna())\n",
    "epu.columns = [\"CNEPU\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPRD    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geopolitical Risk Data:\n",
    "url = \"https://www.matteoiacoviello.com/gpr_files/data_gpr_daily_recent.xls\"\n",
    "resp = requests.get(url)\n",
    "output = open('gpr.xls', 'wb')\n",
    "output.write(resp.content)\n",
    "output.close()\n",
    "\n",
    "gpr = pd.read_excel(\"./gpr.xls\", parse_dates=[\"date\"])\n",
    "gpr.date = pd.to_datetime(gpr.date)\n",
    "gpr.set_index(gpr.date, inplace = True)\n",
    "gpr.drop(columns = [\"date\"], inplace = True)\n",
    "gprd = pd.DataFrame(gpr.GPRD, index=gpr.index)\n",
    "np.sum(gprd.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = pd.concat([gprd, epu], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Opinion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gtrends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrends = pd.read_excel(\"./gtrends.xlsx\", parse_dates=[\"Date\"])\n",
    "gtrends = gtrends.set_index(gtrends.Date)\n",
    "gtrends.drop(columns=[\"Date\"], inplace=True)\n",
    "nulls = [type(gtrends[\"gtrends\"][i])==str for i in range(len(gtrends))]\n",
    "gtrends.iloc[nulls, 0] = np.nan\n",
    "gtrends[\"gtrends\"] = gtrends.gtrends.astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_excel(\"./tweets.xlsx\", sheet_name=\"tweets\")\n",
    "tweets = tweets.set_index(tweets.Date)\n",
    "tweets.drop(columns=[\"Date\"], inplace=True)\n",
    "nulls = [type(tweets[\"tweet\"][i])!=int for i in range(len(tweets))]\n",
    "tweets.iloc[nulls, 0] = np.nan\n",
    "tweets[\"tweet\"] = tweets.tweet.astype(float)\n",
    "tweets = tweets.interpolate(method = \"spline\", order = 3, s = 0.)\n",
    "np.sum(tweets.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_opinion = pd.concat([gtrends, tweets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Data in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [blockchain_info, finecon, risks, public_opinion, rv_total]\n",
    "data_full = pd.concat(sources, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [data_full.loc[data_full[i].notna().to_numpy()].index[0] for i in data_full.columns]\n",
    "end = [data_full.loc[data_full[i].notna().to_numpy()].index[-1] for i in data_full.columns]\n",
    "idx = pd.date_range(start = max(start), end = min(end), freq='D')\n",
    "data_full = data_full.loc[idx]\n",
    "data_full = data_full.fillna(method='ffill')\n",
    "# data_full.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_full.isna().sum().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Fill missing data by interpolation:\n",
    "sources = [blockchain_info, finecon, risks, rv_total, public_opinion]\n",
    "blockchain_info, finecon, risks, rv_total, public_opinion = \\\n",
    "    [fill_missing_data(i, \"1d\") for i in sources]\n",
    "data = pd.concat(sources, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "returns    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check the Data:\n",
    "np.sum(data_full[\"CNEPU\"] == epu.CNEPU.loc[data_full.index]) \\\n",
    "    == data_full.shape[0]\n",
    "np.sum(btc_ret.loc[data_full.index]==data_full[[\"returns\"]])==len(data_full)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.to_excel(\"data_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATRCT', 'AVBLS', 'BLCHS', 'CPTRA', 'CPTRV', 'DIFF', 'ETRAV', 'ETRVU',\n",
       "       'HRATE', 'MIREV', 'MKPRU', 'MKTCP', 'MWNTD', 'MWNUS', 'MWTRV', 'NADDU',\n",
       "       'NTRAN', 'NTRAT', 'NTRBL', 'NTREP', 'TOTBC', 'TOUTV', 'TRFEE', 'TRFUS',\n",
       "       'TRVOU', 'FFER', 'BTC=F', 'CL=F', 'CNYUSD=X', 'NDAQ', 'SPY', 'XRP-USD',\n",
       "       '^DJI', '^GVZ', '^VIX', 'GPRD', 'CNEPU', 'gtrends', 'tweet', 'rv_d',\n",
       "       'rv_w', 'rv_m', 'returns'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "dd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
